# -*- coding: utf-8 -*-
"""Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GV5ADmXaND-efPk39S3L_-ai3svqdo1X
"""

!wget --no-check-certificate \
  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip
import zipfile,os,time
import shutil
import tensorflow as tf
import math
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,Activation
import numpy as np
localfile="/tmp/rockpaperscissors.zip"
zipfolder=zipfile.ZipFile(localfile,'r')
zipfolder.extractall('/tmp')
zipfolder.close()

datadir='/tmp/rockpaperscissors/rps-cv-images';
basedatadir="/tmp/data"
paperdir="/paper"
rockdir="/rock"
scissorsdir="/scissors"
train_val_dir=["/train","/validation"]
dirRPS=[paperdir,rockdir,scissorsdir]
for train_val in train_val_dir:
  for dirName in dirRPS:
    # buat directory temporary untuk masing folder dan membaginya menjadi train dan validation
    os.makedirs(basedatadir+train_val+dirName,exist_ok=True)

# membagi data menjadi data validasi dan training
for dirName in dirRPS:
  allfiles=os.listdir(datadir+dirName)
  # pembagian data antara trainfiles 60% dan validation 40%
  trainfiles,valfiles= np.split(np.array(allfiles),[(math.ceil(len(allfiles)*0.6))])
  # print(len(trainfiles))
  # membagi untuk masing - masing train dan validation
  train_FileNames = [datadir+dirName+"/"+ name for name in trainfiles]
  val_FileNames = [datadir+dirName+ "/"+ name for name in valfiles]
  
  # copy file ke folder data train dan validation
  for name in train_FileNames:
    shutil.copy(name,basedatadir+"/train"+dirName)
  for name in val_FileNames:
    shutil.copy(name,basedatadir+"/validation"+dirName)
  while len(os.listdir(basedatadir+"/train"+dirName))==0 or len(os.listdir(basedatadir+"/validation"+dirName))==0 :
    time.sleep(0.5)

trainDir= basedatadir+"/train"
valDir=basedatadir+"/validation"


trainDataGenerator = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    shear_range = 0.2,
                    fill_mode = 'nearest'
                    )

valDataGenerator = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    shear_range = 0.2,
                    fill_mode = 'nearest'
                    )

class CustomCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self,epoch,log={}):
    if(log['accuracy']>=0.95) :
      print("\n Menghentikan Proses Training...\n Akurasi Model 95% telah dicapai")
      self.model.stop_training=True

trainGenerator=trainDataGenerator.flow_from_directory(
    trainDir,  # direktori data
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        class_mode='categorical'
)
valGenerator=valDataGenerator.flow_from_directory(
    valDir,  # direktori data  validation
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        class_mode='categorical'
)
model = tf.keras.models.Sequential()
# input_shape ku ubah dari (150,150,3) =
model.add(Conv2D(32, (3, 3), input_shape=(150,150,3), padding='same',activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(Dense(256,activation='relu'))
model.add(Dropout(0.4))
model.add(Dense(3,activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=['accuracy'])
model.fit(
      trainGenerator,
      steps_per_epoch=16,  # berapa batch yang akan dieksekusi pada setiap epoch
      epochs=20,
      validation_data=valGenerator, # menampilkan akurasi pengujian data validasi
      validation_steps=3,  # berapa batch yang akan dieksekusi pada setiap epoch
      verbose=2,
      callbacks=[CustomCallback()]
      )

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
import tensorflow as tf
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
upload= files.upload()

testDataGenerator = ImageDataGenerator(
                    rescale=1,
                    rotation_range=20,
                    horizontal_flip=True,
                    vertical_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest'
                    )
for file_upload in upload.keys():
  path=file_upload
  img=image.load_img(path,target_size=(150,150))
  imgplot=plt.imshow(img)
  x=image.img_to_array(img)
  # print(x)
  x=np.expand_dims(x,axis=0)
  images=np.vstack([x])
  # print(testDataGenerator.standardize(images))
  classes=model.predict(images,batch_size=10)

  # print(classes[0])
  if classes[0][0] == 1 :
    print("paper")
  elif classes[0][1]==1:
    print("rock")
  elif classes[0][2]==1:
    print("scissors")
  else :
    print("unknown Image")